---
title: "Chronological age Prediction Challenge 1.0 (epiclock1.0)"
subtitle: "Compte-rendu à compléter"
author: "Florent Chuffart"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
---

```{r, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(collapse=TRUE, comment = "#>", fig.width=9, fig.height=6, eval=TRUE, echo=FALSE, results="hide")
``` 

Ce document propose deux méthodes pour résoudre le *data challenge* `expred3.0` disponible ici : 

https://www.codabench.org/competitions/1692/?secret_key=439a40e9-9de7-4336-918f-ac983d5dd22c

L’**objectif** est double : 

1. on cherche à expliquer l’expression du gène age dans le jeu de données `data_train` ;
2. pour prédire les valeurs d’expression du gène age dans le jeu de données `data_test`.

Dans ce document nous allons essentiellement travailler du le jeu de données d’apprentissage `data_train`.

Nous allons définir deux méthodes : la première se fonde sur la méthode *Surely Independant Screening*, la seconde sur la méthode de sélection de variable *step forward*.

Nous allons mettre en oeuvre une stratégie de validation croisée pour fixer les hyper-paramètres de ces deux méthodes.

Finalement, nous confronterons les résultats obtenus sur le jeu de données d’apprentissage par validation croisée avec ceux obtenus en ligne sur le jeu de données de test.

# Statistiques descriptives

**Le jeu de donnée `data_train`**

```{r loading_data, echo=TRUE, results="verbatim"}
data_train = readRDS(file = "data_train.rds")
data_test = readRDS(file = "data_test.rds")
dim(data_train)
dim(data_test)
head(data_train[,1:6])
table(data_train$sex)
table(data_train$histology)
head(data_train[,4:9])
head(data_train[,1004:1009])
```

**Distribution de l’age dans `data_train`**

```{r distr_als2, echo=TRUE, results="verbatim"}
layout(matrix(1:2, 1), respect=TRUE)
plot(density(data_train$age))
```

**Distribution du transcriptome et du méthylome dans `data_train`**

```{r distr_data_rain, echo=TRUE, results="verbatim"}
layout(matrix(1:2, 1), respect=TRUE)
plot(density(as.matrix(data_train[,4:1003]))   , main="Transcriptome (log2(counts+1))")
plot(density(as.matrix(data_train[,1004:2003])), main="Methylome")

plot(density(as.matrix(2^(data_train[,4:1003])))   , main="Transcriptome (counts)")
zd = t(as.matrix(((t(data_train[,4:1003]) - apply(data_train[,4:1003], 2, mean))/ apply(data_train[,4:1003], 2, sd))))
plot(density(zd), main="Transcriptome (z-score)")
lines(density(rnorm(100000)), lty=2, col="grey")
```

Nous considérerons que la distribution de l’expression de chaque gène est **gaussienne**.


# Méthode SIS

La method SIS [Shurely Independant Screening, Zhang HH. J R Stat Soc Series B Stat Methodol. 2008] appliquée au *transcriptome* (définir) consiste à 
i) réaliser autant de regressions linéaires simples du type $age \sim probe$ qu’il y a de gènes ; 
ii) selectionner les gènes correspondant aux meilleurs modèles ($probe_1, probe_2, probe_3 ...$) ; 
iii) considérer le modèle linéaire multivarié $age \sim probe_1 + probe_2 + probe_3 + ...$


1. Corrigez le code suivant pour répondre aux attentes énoncées : 

```{r screening, echo=TRUE, results="verbatim"}
siscreening = function(data_train) {
  probes = colnames(data_train)[3:2500] # to be update
  pval_fisher = c()
  beta = c()
  r2 = c()
  for (p in probes) {
    m = lm(data_train[,"age"]~1)        # to be update
    pval_fisher = c(pval_fisher, 1)     # to be update, tips: look at anova(m)[,]
    beta = c(beta, m$coefficients[[1]]) # to be update
    r2 = c(r2, summary(m)$r.squared)
  }
  names(pval_fisher)  = probes
  names(beta)         = probes  
  names(r2)           = probes  
  return(data.frame(pval_fisher=pval_fisher, beta=beta, r2=r2))
}

sis_res = siscreening(data_train)  
head(sis_res)
```

2. Tracez le **volcano plot** correspondant au screening :  en abscisse on trace le beta de chaque modéle indépendant et en ordonée le $-log10(pval_{fisher})$ correspondant. Pensez aux titres. Commentez.


3. Tracez en abscisse le $R^2$ de chaque modéle indépendant et en ordonée le $-log10(pval_{fisher})$ correspondant. Pensez aux titres. Commentez.

```{r volcano1, echo=TRUE, results="verbatim"}
layout(matrix(1:2, 1), respect=TRUE)
plot(sis_res$beta, -log10(sis_res$pval), main="Volcano plot")
# idx = -log10(sis_res$pval) > 30
# text(sis_res[idx,]$beta, -log10(sis_res[idx,]$pval), rownames(sis_res)[idx], col=2)
plot(sis_res$r2, -log10(sis_res$pval))                  
```

4. Commentez le code et le graphique suivant : 

```{r sis_1, echo=TRUE, results="verbatim"}
m = lm(age~cg00329615, data_train)
layout(matrix(1:2, 1), respect=TRUE)
plot(data_train[,"cg00329615"],data_train[,"age"], main=paste0("age~cg00329615 R^2: ", signif(summary(m)$r.squared, 3)))
abline(m,col="red")
```


5. Construisez un modèle avec les $8$ meilleurs candidats obtenus par SIS (les $R^2$ les plus petits). Calculez le $R^2$ de ce modèle.

```{r head8_sis, fig.height=9, echo=TRUE, results="verbatim"}
sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
head(sis_probes,8)
```


6. Utilisez la fonction `pairs` et tracez les correlations2 à 2 des 8 meilleurs obtenus avec la méthode SIS. Commentez

```{r pairs8_sis, fig.height=9, echo=TRUE, results="verbatim"}
pairs(data_train[,sis_probes[1:8]], main="pair_plot")
```

7. Analysez la fonction suivante. Que fait-elle ? Quelles valeurs peuvent prendre l’argument `i` ?

```{r model_sis_i, echo=TRUE, results="verbatim", echo=TRUE, results="verbatim"}
model_sis_i = function(data_train, i, screening_func=siscreening) { 
  print(paste0("model SIS ", i))
  # independant screening on train
  sis_res = screening_func(data_train)
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  # build model
  formula = as.formula(paste0(c("age~gender",sis_probes[0:i]),collapse="+"))
  m = lm(formula, data_train)
  return(m)
}
```

8. Construisez tour à tour les modéles `sis_0`, `sis_1`, `sis_2`, ..., `sis_50`. Observez l’évolution du $R^2$ dans ces modèles. Commentez.

```{r sis_n, echo=TRUE, results="hide"}
r2_sis = c()
for (i in 0:50) {
 # m = ... 
 # r2_sis = c(r2_sis, summary(m)$r.squared)
}
# plot(0:50, r2_sis)
```





# Méthode *step forward* 

Nous venons de voir que tous les gènes n’apportent pas la même quantité d’information "nouvelle". Nous allons tirer partie de la méthode de sélection variables *step forward* pour sélectionner les gènes qui apportent de l’information "nouvelle". En effet, nous allons partir du modèle nul et ajouter un à un les gènes, parmi les 50 meilleurs gênes obtenu grace à la méthode SIS, qui augmentent considérablement la qualité du modèle.


1. Analyser le code suivant. Que fait la fontion `step` ? Que contient la variable retournée `step_probes` ?

```{r step_model, echo=TRUE, results="hide"}
stepforward = function(data_train, sis_probes, nb_sis_probes=50, trace=0, k=2) {
  m_lo = lm(age ~ 1, data=data_train[,c("age", sis_probes[1:nb_sis_probes])])
  m_up = lm(age ~ ., data=data_train[,c("age", sis_probes[1:nb_sis_probes])])
  m_fwd = step(m_lo, method="forward", scope=list(upper=m_up,lower=m_lo), trace=trace, k=k)  
  # print(m_fwd$call)
  step_probes = names(m_fwd$coefficients)[-1]
}

step_probes = stepforward(data_train, sis_probes, trace=1)
step_probes
```

2. Utilisez la fonction `pairs` popurt tracer les correlations2 à 2 des 8 meilleurs obtenus avec la méthode `step`.

```{r pairs2, echo=TRUE, results="verbatim", fig.height=9}
layout(1, respect=TRUE)
pairs(data_train[,step_probes[1:8]], main="pair_plot")
```

3. Affichez sur le volcano plot du screening indépendant les génes selectionné par `stepforward`. Commentez.

```{r volcano2, echo=TRUE, results="verbatim"}
layout(matrix(1:2, 1), respect=TRUE)
plot(sis_res$beta, -log10(sis_res$pval))
idx = step_probes
text(sis_res[idx,]$beta, -log10(sis_res[idx,]$pval), idx, col=2)
```


4. Analysez la fonction suivante. Que fait-elle ? Quelles valeurs peuvent prendre l’argument `i` ?

```{r model_stp_i, echo=TRUE, results="verbatim"}
model_stp_i = function(data_train, i, step_func=stepforward) { 
  print(paste0("model step ", i))
  # independant screening on train
  sis_res = msiscreening(data_train)
  sis_probes = rownames(sis_res)[order(sis_res$pval_fisher)]
  # step
  step_probes = step_func(data_train, sis_probes, trace=0, k=0)
  # build model
  formula = as.formula(paste0(c("age~1",step_probes[0:i]),collapse="+"))
  m = lm(formula, data_train)
  return(m)
}
```

5. Construisez tour à tour les modéles `stp_0`, `stp_1`, `stp_2`, ..., `stp_20`. Observez l’évolution du $R^2$ dans ces modèles. Comparez avec l’évolution du $R^2$ obetnue avec les modèles `sis_0`, `sis_1`, `sis_2`, ..., `sis_50`. Commentez.

```{r step_n, echo=TRUE, results="verbatim"}
r2_stp <- c()
for(i in 0:20){
  # m = ...
  # r2_stp = c(r2_stp, summary(m)$r.squared)
}

# plot(0:50, r2_sis, ylim=c(0,1))
# points(0:20, r2_stp, col=2)
```





**Mais où s’arrêter ? Comment contrôler le sur-apprentissage ?**












# Validation croisée

...

# Bootstrap

...




# Annexe : la *mémoïsation*

**Définition** : *En informatique, la mémoïsation est la mise en cache des valeurs de retour d’une fonction selon ses valeurs d’entrée. Le but de cette technique d’optimisation de code est de diminuer le temps d’exécution d’un programme informatique en mémorisant les valeurs retournées par une fonction.* 

https://fr.wikipedia.org/wiki/Mémoïsation


```{r memoise_demo, echo=TRUE, eval=FALSE}
sis_res = siscreening(data_train)  
msiscreening = memoise::memoise(siscreening)
sis_res = msiscreening(data_train)  
sis_res = msiscreening(data_train)  
sis_res = msiscreening(data_train)  
sis_res = msiscreening(data_train)  
msiscreening = memoise::memoise(siscreening)
sis_res = msiscreening(data_train)  
sis_res = msiscreening(data_train)  
sis_res = msiscreening(data_train)  
```

**Exercice** : predisez le comportement des codes suivants : 

```{r memoise_exo, echo=TRUE, eval=FALSE}
sleep = Sys.sleep
msleep = memoise::memoise(sleep)
sleep(3)
sleep(3)
msleep(3)
msleep(3)
msleep = memoise::memoise(sleep)
msleep(3)

mrnorm = memoise::memoise(rnorm)
rnorm(1)
mrnorm(1)
```

**ATTENTION** : 

  - La *memoïsation* repose sur le calcul d’une clef de hachage des variables passées en argument de la fonction à mémoïser. Si les valeurs des variables sont trop volumineuses, le caclcul de la clef peut prendre beaucoup de temps. 
  - Si la fonction à mémoïser est stochastique alors la fonction mémoïsée perd sa stochasticité. Cette dernière pratique n’a pas forcément de sens. 


# Information de session

```{r, results="verbatim"}
sessionInfo()
```



